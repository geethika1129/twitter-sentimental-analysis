# -*- coding: utf-8 -*-
"""twitter analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gc8ojbVmNTSEZoGhM1AUIC9lxlojtB8L
"""

import pandas as pd
from pyspark.sql.functions import udf, col
from pyspark.sql.types import StringType
import os

silver_path = os.getenv("silver")
gold_path = os.getenv("gold")
df=pd.read_csv("sample_data/Tweets.csv")

df.head

dfn=df[['text','airline_sentiment']]
print(dfn.shape)

dfn["airline_sentiment"].value_counts()

labels=dfn.airline_sentiment.factorize()

labels

tweet=dfn.text.values

tweet

from tensorflow import keras
from keras.models import Model
from keras.layers import Dense
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=5000)

tokenizer.fit_on_texts(tweet)

encoded_docs = tokenizer.texts_to_sequences(tweet)

from tensorflow.keras.preprocessing.sequence import pad_sequences

padded_sequence = pad_sequences(encoded_docs, maxlen=200)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D
from tensorflow.keras.layers import Embedding

vocab_size = len(tokenizer.word_index) + 1
embedding_vector_length = 32
model = Sequential()
model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])

print(model.summary())

history = model.fit(padded_sequence,labels[0],validation_split=0.2, epochs=5, batch_size=32)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')

plt.legend()
plt.show()

def predict_sentiment(text):
    tw = tokenizer.texts_to_sequences([text])
    tw = pad_sequences(tw,maxlen=200)
    prediction = int(model.predict(tw).round().item())
    print("Predicted label: ", labels[1][prediction])


test_sentence1 = "I enjoyed my journey on this flight."
predict_sentiment(test_sentence1)


df_silver = spark.read.format("delta").load(silver_path)

predict_sentiment_udf = udf(predict_sentiment, StringType())

df_gold = df_silver.withColumn("predicted_sentiment", predict_sentiment_udf(col("text")))

df_gold.write.format("delta").mode("overwrite").save(gold_path)
